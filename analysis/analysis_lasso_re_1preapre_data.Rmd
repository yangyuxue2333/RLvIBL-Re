---
title: "Analysis Lasso-Re (Prepare)"
date: "`r Sys.Date()`"
author: "Cher Yang"
output:
  html_document:
    code_folding: hide
    theme: yeti
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
  word_document:
    toc: yes
    toc_depth: '3'
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
library(magrittr)
library(ggplot2)
library(ggthemes)
library(ppcor)
library(reshape2)
library(groupdata2)
library(knitr)       # kable()

#library(gglasso)
library(glmnet)
library(ggsci)
library(viridis)
library(ggExtra)
library(kableExtra)
library(xtable)
library(ggrepel)
library(scales)
library(car)
library(pROC)
library(patchwork)      # Multi-plot alignment
library(brainconn)
library(igraph)
library(network)
library(brainconn)
library(brainGraph)
library(RColorBrewer)
library(networkD3)
library(ggpubr)
library(DescTools)
library(plotly)
#library(data.table)
library(rsample)   
library(purrr)
library(dplyr)
library(ggplot2)
library(scales)
library(mlbench)
library(kernlab)
library(sessioninfo)
rm(list=ls())
```

**Analysis parameters:**

*rsfMRI data Parameters:*

-   rsfMRI: R1S1 mr_pcorr.txt file

-   Z norm before load: False

-   upsampling: **UP**

# Load Data

Create the Group-Level Regressor Matrix $X$

We now need to load the group level data. In essence, to corresponds to
create a matrix *X* in which every individual is a row and every columns
is a different ROI-to-ROI connection.

```{r}
  CONN_FILE_PATH = "../data/connectivity_matrix/REST1"
  SES_FILE_PATH = "ses-01/mr_pcorr.txt"
  POWER_FILE_PATH = "../data/power_2011.csv"
  
  power2011 <- read_csv(POWER_FILE_PATH, 
                      col_types = cols(ROI=col_double(),
                                       X = col_double(),
                                       Y = col_double(),
                                       Z = col_double(),
                                       Network = col_double(),
                                       Color = col_character(),
                                       NetworkName = col_character())) %>%
  dplyr::select(ROI, X, Y, Z, Network, Color, NetworkName)


  # color setup
  #power2011 %>% mutate(Color = factor(Color)) %>%
  power2011$Color <- recode_factor(power2011$Color, White="#8DD3C7", 
                                  Cyan="#E0FFFF", 
                                  Orange="#FF8C00", 
                                  Purple="#9370DB", 
                                  Pink="#FFB6C1", 
                                  Red="#FF6347", 
                                  Gray="#808080", 
                                  Teal="#008080", 
                                  Blue="#87CEFA", 
                                  Yellow="#FFFF66", 
                                  Black="#000000", 
                                  Brown="#8B4513", 
                                  `Pale blue`="#4682B4", 
                                  Green="#3CB371") 
  power2011$Color <- as.character(power2011$Color)
```

Load dependent variable: best fit model and find common subjects IDs

```{r}
# rest data subjects
rest_subjects = as.data.frame(x  = Sys.glob(paths = "../data/connectivity_matrix/REST1/*")) 
colnames(rest_subjects) <- c('subject_id')  

# clean subject id
rest_subjects <- rest_subjects %>%
  mutate(subject_id = purrr::map_chr(subject_id, ~strsplit(., "/")[[1]][5])) %>%
  mutate(HCPID = paste(str_replace(subject_id, pattern = "sub-", ""), sep = "_", "fnca"))
```

```{r}
dvs <- read_csv("../data/actr_maxLL.csv",
                col_types = cols(
                  .default = col_double(),
                  HCPID = col_character(),
                  BestModel = col_character(), 
                  LL.diff = col_double()
                )) %>% 
  # find common subject ID that both rest and task data are available
  inner_join(rest_subjects, by = "HCPID") %>%
  dplyr::select(HCPID, BestModel, LL.diff) %>%
  arrange(HCPID) %>%
  mutate(Y = as.numeric(as.factor(BestModel)) -1,  # model1 = 0, model2 = 1
         HCPID = factor(HCPID), 
         BestModel=factor(BestModel))

dvs %>% group_by(BestModel) %>% count()
```

Up-sampling: make sure equal group members

```{r}
dvs.up <- groupdata2::upsample(
  dvs,
  cat_col = "BestModel",
  id_col = "HCPID",
  id_method = "n_ids", 
  mark_new_rows = FALSE
)

dvs.up %>% group_by(BestModel) %>% count()
```


Find common subjects ids
```{r}
common_subjects <- dvs.up %>% left_join(rest_subjects)
common_subject_ids <- common_subjects$subject_id
```
Find subject ID that both rest and task data are available. We have common subjects: N = `r length(common_subject_ids)`

```{r}
  # Start creating $X$
  NOFLY <- c()
  SUBJS <- c()
  cols <- outer(power2011$ROI, power2011$ROI, function(x, y) {paste(x, y, sep="-")})
  cols %<>% as.vector
  
  connection <- function(x, y) {
    paste(min(x, y), max(x, y), sep="-")
  }
  
  vconnection <- Vectorize(connection)
  
  Mode <- function(x, na.rm=F) {
    if (na.rm) {
      x = x[!is.na(x)]
    }
    ux <- unique(x)
    return(ux[which.max(tabulate(match(x, ux)))])
  }
  
  reduced_power2011 <- power2011 %>% 
    dplyr::select(Network, NetworkName) %>%
    group_by(Network) %>%
    summarize(Network = mean(Network), NetworkName = Mode(NetworkName))
  
  connection_name <- function(x, y) {
    first <- min(x, y)
    second <- max(x, y)
    paste(reduced_power2011 %>% filter(Network == first) %>% dplyr::select(NetworkName) ,
          reduced_power2011 %>% filter(Network == second) %>% dplyr::select(NetworkName),
          sep="-")
    
  }
  
  vconnection_name <- Vectorize(connection_name)
  
  connection_name2 <- function(x, y) {
    first <- min(x, y)
    second <- max(x, y)
    paste(reduced_power2011$NetworkName[reduced_power2011$Network == first],
          reduced_power2011$NetworkName[reduced_power2011$Network == second],
          sep="-")
    
  }
  
  vconnection_name2 <- Vectorize(connection_name2)
  
  
  nets <- outer(power2011$Network, power2011$Network, vconnection)
  nets %<>% as.vector
  netnames <- outer(power2011$Network, power2011$Network, vconnection_name2)
  netnames %<>% as.vector
  
  
  n <- length(common_subject_ids) #length(grep("sub-*", dir(CONN_FILE_PATH)))
  C <- matrix(data = rep(0, length(cols)*n), nrow =  n)
  
  j <- 1
  
  R <- NULL
  PR <- NULL
  
  #for (sub in dir(CONN_FILE_PATH)[grep("sub-*", dir(CONN_FILE_PATH))]) {
  for (sub in common_subject_ids) {
    #SUBJS %<>% c(strsplit(sub, "-")[[1]][2])
    M <- paste(CONN_FILE_PATH, 
               sub, 
               SES_FILE_PATH, sep="/") %>%
      read_csv(skip = 1,
               col_names = F,
               col_types = cols(
                 .default = col_double(),
                 X1 = col_character()
               )) %>%
      as.matrix() 
    v <- as_vector(M[,2:265])  # v spreads M column-wise. M is symmetrical, so it should not matter, but better not risk it
    C[j,] <- v
    if (length(v[is.na(v)]) > 0) {
      print(paste("NA detected in sub", sub))
      NOFLY %<>% c(sub)  # Addes sub to NOFLY list
    }
    
    j <- j + 1
  }
  C <- apply(C, 2, FUN=as.numeric)
```

## Define the Networks

```{r}
NOI <- c(
  "Uncertain",
  "Sensory/somatomotor Hand",
  "Sensory/somatomotor Mouth",
  "Cingulo-opercular Task Control",
  "Auditory",
  "Default mode",
  "Memory retrieval?",
  "Ventral attention",
  "Visual",
  "Fronto-parietal Task Control",
  "Salience",
  "Subcortical",
  "Cerebellar",
  "Dorsal attention"
)

COI <- outer(NOI, 
             NOI, 
             function(x, y) {paste(x, y, sep="-")}) %>% as.vector()
```

The first censor vector simply removes the redundant columns (since the
connectivity from *A* to *B* is the same as the connectivity of *B* to
*A*) and the self-correlations:

```{r}
censor <- outer(power2011$ROI, 
                power2011$ROI, 
                function(x, y) {x < y}) %>% as.vector()
```

The second censor vector removes unlikely functional connections: Those
with a partial correlation value $|r| < 0.05|$.

```{r}
censor2 <- colMeans(C) %>% abs() > 0.05
```

Now, we combine the censor vectors in a tibble that contains all of the
relevant information about each column in *C*.

```{r}
order <- tibble(index = 1:length(nets), 
                network = nets, 
                network_names = netnames,
                connection = cols, 
                censor=censor,
                censor2 = censor2)
order %<>% arrange(network)
```

And we remove all entries for each a censor vector is `FALSE` (we also
create a grouping factor *G*, in case in the future we want to use
*Group* Lasso).

```{r}
I <- order %>%
  filter(censor == TRUE) %>%
  filter(censor2 == TRUE) %>%
  filter(network_names %in% COI) %>%
  dplyr::select(index) 

G <- order %>%
  filter(censor == TRUE) %>%
  filter(network_names %in% COI) %>%
  dplyr::select(network) 
# G is the real grouping factor for Lasso!
```

As a last step, we create the "real" regressor matrix $X$, which is the
proper subset of $C$ after removing all of the censored columns. Also,
we need to load the dependent variable. In this case, it is a binary
variable that determines which strategy model best fits the behavioral
data of an individual, whether it is the "memory" strategy ($Y = 1$) or
the "procedural" strategy ($Y = 2$).

```{r}
X <- C[,as_vector(I)]
```


Now we select only the rows of $X$ and the values of $Y$ for which we
have both rsfMRI and model data.

The dimension of X is: `r dim(X)`

Finally, we transform the dependent variable $Y$ into a binary numeric
variable with values $(0, 1)$, so that we can use logistic regression.

```{r}
Y <- dvs.up$Y
```

> Quality and Characteristics of $X$ and $Y$

Let's do some visualization and analysis of our indepedenent and
dependet variables, just to ensure there are no obvious problems.

> Collinearity of Connectivity Regressors $X$

The regressors $X$ is certainly multi-collinear; that is a consequence
of having a large number of predictors $p > n$, which, in turn, is one
of the reasons why we are using Lasso. Too much collinearity, however,
could be really bad and push Lasso towards selecting non-optimal
regressors. To gather a sense of how much collinearity we have, we can
plot the distribution of correlations among regressors:

```{r}
corX <- cor(X)
distCor <- as_vector(corX[lower.tri(corX, diag = F)])
distTibble <- as_tibble(data.frame(R=distCor))

ggplot(distTibble, aes(x=R)) +
  geom_histogram(col="white", alpha=0.5, binwidth = 0.05) +
  theme_pander() +
  ylab("Number of Correlations") +
  xlab("Correlation Value") +
  ggtitle("Distribution of Correlation Values Between Regressors")
```

All in all, the collinearity is not that bad---all regressors are
correlated at $|r| < 0.25$, and most of them are correlated at
$|r| < 0.1$, with a peak at $r = 0$.

## Distribution of Group Classes

And now, let's visualize the histogram of the dependent variable we are
trying to predict:

```{r}
ggplot(dvs %>% drop_na(), aes(x = BestModel, fill=BestModel)) +
  geom_bar(col="white", alpha=0.5, width = .5) +
  scale_fill_nejm() +
  xlab("Strategy") +
  ylab("Number of Participants") +
  scale_x_discrete(labels=c( "model1" = "Declarative",  "model2" = "Procedural")) +
  ggtitle("Distribution of Strategy Use") +
  theme_pander(lp = "none")

```

Because the classes are not equally distributed, and participants are
more likely to use the memory strategy ($Y=0$) than the procedural one
($Y = 1$), we would need to adjust the weights of our Lasso model.

------------------------------------------------------------------------

Save RData

```{r}
save.image(file = "../data/__cache__/worksapce_prepare_data.RData")
```
